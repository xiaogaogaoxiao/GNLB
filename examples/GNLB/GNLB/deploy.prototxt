input: "data"
input_dim: 1
input_dim: 3
input_dim: 400
input_dim: 400

layer {
	bottom: "data"
	top: "conv1"
	name: "conv1"
	type: "Convolution"
	convolution_param {
		num_output: 64
		kernel_size: 7
		pad: 3
		stride: 2
		bias_term: false
	}
}

layer {
	bottom: "conv1"
	top: "conv1"
	name: "bn_conv1"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "conv1"
	top: "conv1"
	name: "scale_conv1"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	top: "conv1"
	bottom: "conv1"
	name: "conv1_relu"
	type: "ReLU"
}

layer {
	bottom: "conv1"
	top: "pool1"
	name: "pool1"
	type: "Pooling"
	pooling_param {
		kernel_size: 3
		stride: 2
		pool: MAX
	}
}

layer {
	bottom: "pool1"
	top: "res2a_branch1"
	name: "res2a_branch1"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res2a_branch1"
	top: "res2a_branch1"
	name: "bn2a_branch1"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res2a_branch1"
	top: "res2a_branch1"
	name: "scale2a_branch1"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "pool1"
	top: "res2a_branch2a"
	name: "res2a_branch2a"
	type: "Convolution"
	convolution_param {
		num_output: 64
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res2a_branch2a"
	top: "res2a_branch2a"
	name: "bn2a_branch2a"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res2a_branch2a"
	top: "res2a_branch2a"
	name: "scale2a_branch2a"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	top: "res2a_branch2a"
	bottom: "res2a_branch2a"
	name: "res2a_branch2a_relu"
	type: "ReLU"
}

layer {
	bottom: "res2a_branch2a"
	top: "res2a_branch2b"
	name: "res2a_branch2b"
	type: "Convolution"
	convolution_param {
		num_output: 64
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res2a_branch2b"
	top: "res2a_branch2b"
	name: "bn2a_branch2b"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res2a_branch2b"
	top: "res2a_branch2b"
	name: "scale2a_branch2b"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	top: "res2a_branch2b"
	bottom: "res2a_branch2b"
	name: "res2a_branch2b_relu"
	type: "ReLU"
}

layer {
	bottom: "res2a_branch2b"
	top: "res2a_branch2c"
	name: "res2a_branch2c"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res2a_branch2c"
	top: "res2a_branch2c"
	name: "bn2a_branch2c"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res2a_branch2c"
	top: "res2a_branch2c"
	name: "scale2a_branch2c"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res2a_branch1"
	bottom: "res2a_branch2c"
	top: "res2a"
	name: "res2a"
	type: "Eltwise"
}

layer {
	bottom: "res2a"
	top: "res2a"
	name: "res2a_relu"
	type: "ReLU"
}

layer {
	bottom: "res2a"
	top: "res2b_branch2a"
	name: "res2b_branch2a"
	type: "Convolution"
	convolution_param {
		num_output: 64
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res2b_branch2a"
	top: "res2b_branch2a"
	name: "bn2b_branch2a"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res2b_branch2a"
	top: "res2b_branch2a"
	name: "scale2b_branch2a"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	top: "res2b_branch2a"
	bottom: "res2b_branch2a"
	name: "res2b_branch2a_relu"
	type: "ReLU"
}

layer {
	bottom: "res2b_branch2a"
	top: "res2b_branch2b"
	name: "res2b_branch2b"
	type: "Convolution"
	convolution_param {
		num_output: 64
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res2b_branch2b"
	top: "res2b_branch2b"
	name: "bn2b_branch2b"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res2b_branch2b"
	top: "res2b_branch2b"
	name: "scale2b_branch2b"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	top: "res2b_branch2b"
	bottom: "res2b_branch2b"
	name: "res2b_branch2b_relu"
	type: "ReLU"
}

layer {
	bottom: "res2b_branch2b"
	top: "res2b_branch2c"
	name: "res2b_branch2c"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res2b_branch2c"
	top: "res2b_branch2c"
	name: "bn2b_branch2c"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res2b_branch2c"
	top: "res2b_branch2c"
	name: "scale2b_branch2c"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res2a"
	bottom: "res2b_branch2c"
	top: "res2b"
	name: "res2b"
	type: "Eltwise"
}

layer {
	bottom: "res2b"
	top: "res2b"
	name: "res2b_relu"
	type: "ReLU"
}

layer {
	bottom: "res2b"
	top: "res2c_branch2a"
	name: "res2c_branch2a"
	type: "Convolution"
	convolution_param {
		num_output: 64
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res2c_branch2a"
	top: "res2c_branch2a"
	name: "bn2c_branch2a"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res2c_branch2a"
	top: "res2c_branch2a"
	name: "scale2c_branch2a"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	top: "res2c_branch2a"
	bottom: "res2c_branch2a"
	name: "res2c_branch2a_relu"
	type: "ReLU"
}

layer {
	bottom: "res2c_branch2a"
	top: "res2c_branch2b"
	name: "res2c_branch2b"
	type: "Convolution"
	convolution_param {
		num_output: 64
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res2c_branch2b"
	top: "res2c_branch2b"
	name: "bn2c_branch2b"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res2c_branch2b"
	top: "res2c_branch2b"
	name: "scale2c_branch2b"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	top: "res2c_branch2b"
	bottom: "res2c_branch2b"
	name: "res2c_branch2b_relu"
	type: "ReLU"
}

layer {
	bottom: "res2c_branch2b"
	top: "res2c_branch2c"
	name: "res2c_branch2c"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res2c_branch2c"
	top: "res2c_branch2c"
	name: "bn2c_branch2c"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res2c_branch2c"
	top: "res2c_branch2c"
	name: "scale2c_branch2c"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res2b"
	bottom: "res2c_branch2c"
	top: "res2c"
	name: "res2c"
	type: "Eltwise"
}

layer {
	bottom: "res2c"
	top: "res2c"
	name: "res2c_relu"
	type: "ReLU"
}

layer {
	bottom: "res2c"
	top: "res3a_branch1"
	name: "res3a_branch1"
	type: "Convolution"
	convolution_param {
		num_output: 512
		kernel_size: 1
		pad: 0
		stride: 2
		bias_term: false
	}
}

layer {
	bottom: "res3a_branch1"
	top: "res3a_branch1"
	name: "bn3a_branch1"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res3a_branch1"
	top: "res3a_branch1"
	name: "scale3a_branch1"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res2c"
	top: "res3a_branch2a"
	name: "res3a_branch2a"
	type: "Convolution"
	convolution_param {
		num_output: 128
		kernel_size: 1
		pad: 0
		stride: 2
		bias_term: false
	}
}

layer {
	bottom: "res3a_branch2a"
	top: "res3a_branch2a"
	name: "bn3a_branch2a"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res3a_branch2a"
	top: "res3a_branch2a"
	name: "scale3a_branch2a"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	top: "res3a_branch2a"
	bottom: "res3a_branch2a"
	name: "res3a_branch2a_relu"
	type: "ReLU"
}

layer {
	bottom: "res3a_branch2a"
	top: "res3a_branch2b"
	name: "res3a_branch2b"
	type: "Convolution"
	convolution_param {
		num_output: 128
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res3a_branch2b"
	top: "res3a_branch2b"
	name: "bn3a_branch2b"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res3a_branch2b"
	top: "res3a_branch2b"
	name: "scale3a_branch2b"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	top: "res3a_branch2b"
	bottom: "res3a_branch2b"
	name: "res3a_branch2b_relu"
	type: "ReLU"
}

layer {
	bottom: "res3a_branch2b"
	top: "res3a_branch2c"
	name: "res3a_branch2c"
	type: "Convolution"
	convolution_param {
		num_output: 512
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res3a_branch2c"
	top: "res3a_branch2c"
	name: "bn3a_branch2c"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res3a_branch2c"
	top: "res3a_branch2c"
	name: "scale3a_branch2c"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res3a_branch1"
	bottom: "res3a_branch2c"
	top: "res3a"
	name: "res3a"
	type: "Eltwise"
}

layer {
	bottom: "res3a"
	top: "res3a"
	name: "res3a_relu"
	type: "ReLU"
}

layer {
	bottom: "res3a"
	top: "res3b1_branch2a"
	name: "res3b1_branch2a"
	type: "Convolution"
	convolution_param {
		num_output: 128
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res3b1_branch2a"
	top: "res3b1_branch2a"
	name: "bn3b1_branch2a"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res3b1_branch2a"
	top: "res3b1_branch2a"
	name: "scale3b1_branch2a"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	top: "res3b1_branch2a"
	bottom: "res3b1_branch2a"
	name: "res3b1_branch2a_relu"
	type: "ReLU"
}

layer {
	bottom: "res3b1_branch2a"
	top: "res3b1_branch2b"
	name: "res3b1_branch2b"
	type: "Convolution"
	convolution_param {
		num_output: 128
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res3b1_branch2b"
	top: "res3b1_branch2b"
	name: "bn3b1_branch2b"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res3b1_branch2b"
	top: "res3b1_branch2b"
	name: "scale3b1_branch2b"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	top: "res3b1_branch2b"
	bottom: "res3b1_branch2b"
	name: "res3b1_branch2b_relu"
	type: "ReLU"
}

layer {
	bottom: "res3b1_branch2b"
	top: "res3b1_branch2c"
	name: "res3b1_branch2c"
	type: "Convolution"
	convolution_param {
		num_output: 512
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res3b1_branch2c"
	top: "res3b1_branch2c"
	name: "bn3b1_branch2c"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res3b1_branch2c"
	top: "res3b1_branch2c"
	name: "scale3b1_branch2c"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res3a"
	bottom: "res3b1_branch2c"
	top: "res3b1"
	name: "res3b1"
	type: "Eltwise"
}

layer {
	bottom: "res3b1"
	top: "res3b1"
	name: "res3b1_relu"
	type: "ReLU"
}

layer {
	bottom: "res3b1"
	top: "res3b2_branch2a"
	name: "res3b2_branch2a"
	type: "Convolution"
	convolution_param {
		num_output: 128
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res3b2_branch2a"
	top: "res3b2_branch2a"
	name: "bn3b2_branch2a"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res3b2_branch2a"
	top: "res3b2_branch2a"
	name: "scale3b2_branch2a"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	top: "res3b2_branch2a"
	bottom: "res3b2_branch2a"
	name: "res3b2_branch2a_relu"
	type: "ReLU"
}

layer {
	bottom: "res3b2_branch2a"
	top: "res3b2_branch2b"
	name: "res3b2_branch2b"
	type: "Convolution"
	convolution_param {
		num_output: 128
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res3b2_branch2b"
	top: "res3b2_branch2b"
	name: "bn3b2_branch2b"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res3b2_branch2b"
	top: "res3b2_branch2b"
	name: "scale3b2_branch2b"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	top: "res3b2_branch2b"
	bottom: "res3b2_branch2b"
	name: "res3b2_branch2b_relu"
	type: "ReLU"
}

layer {
	bottom: "res3b2_branch2b"
	top: "res3b2_branch2c"
	name: "res3b2_branch2c"
	type: "Convolution"
	convolution_param {
		num_output: 512
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res3b2_branch2c"
	top: "res3b2_branch2c"
	name: "bn3b2_branch2c"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res3b2_branch2c"
	top: "res3b2_branch2c"
	name: "scale3b2_branch2c"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res3b1"
	bottom: "res3b2_branch2c"
	top: "res3b2"
	name: "res3b2"
	type: "Eltwise"
}

layer {
	bottom: "res3b2"
	top: "res3b2"
	name: "res3b2_relu"
	type: "ReLU"
}

layer {
	bottom: "res3b2"
	top: "res3b3_branch2a"
	name: "res3b3_branch2a"
	type: "Convolution"
	convolution_param {
		num_output: 128
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res3b3_branch2a"
	top: "res3b3_branch2a"
	name: "bn3b3_branch2a"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res3b3_branch2a"
	top: "res3b3_branch2a"
	name: "scale3b3_branch2a"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	top: "res3b3_branch2a"
	bottom: "res3b3_branch2a"
	name: "res3b3_branch2a_relu"
	type: "ReLU"
}

layer {
	bottom: "res3b3_branch2a"
	top: "res3b3_branch2b"
	name: "res3b3_branch2b"
	type: "Convolution"
	convolution_param {
		num_output: 128
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res3b3_branch2b"
	top: "res3b3_branch2b"
	name: "bn3b3_branch2b"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res3b3_branch2b"
	top: "res3b3_branch2b"
	name: "scale3b3_branch2b"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	top: "res3b3_branch2b"
	bottom: "res3b3_branch2b"
	name: "res3b3_branch2b_relu"
	type: "ReLU"
}

layer {
	bottom: "res3b3_branch2b"
	top: "res3b3_branch2c"
	name: "res3b3_branch2c"
	type: "Convolution"
	convolution_param {
		num_output: 512
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res3b3_branch2c"
	top: "res3b3_branch2c"
	name: "bn3b3_branch2c"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res3b3_branch2c"
	top: "res3b3_branch2c"
	name: "scale3b3_branch2c"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res3b2"
	bottom: "res3b3_branch2c"
	top: "res3b3"
	name: "res3b3"
	type: "Eltwise"
}

layer {
	bottom: "res3b3"
	top: "res3b3"
	name: "res3b3_relu"
	type: "ReLU"
}

layer {
	bottom: "res3b3"
	top: "res4a_branch1"
	name: "res4a_branch1"
	type: "Convolution"
	convolution_param {
		num_output: 1024
		kernel_size: 1
		pad: 0
		stride: 2
		bias_term: false
	}
}

layer {
	bottom: "res4a_branch1"
	top: "res4a_branch1"
	name: "bn4a_branch1"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res4a_branch1"
	top: "res4a_branch1"
	name: "scale4a_branch1"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res3b3"
	top: "res4a_branch2a"
	name: "res4a_branch2a"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 1
		pad: 0
		stride: 2
		bias_term: false
	}
}

layer {
	bottom: "res4a_branch2a"
	top: "res4a_branch2a"
	name: "bn4a_branch2a"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res4a_branch2a"
	top: "res4a_branch2a"
	name: "scale4a_branch2a"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	top: "res4a_branch2a"
	bottom: "res4a_branch2a"
	name: "res4a_branch2a_relu"
	type: "ReLU"
}

layer {
	bottom: "res4a_branch2a"
	top: "res4a_branch2b"
	name: "res4a_branch2b"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4a_branch2b"
	top: "res4a_branch2b"
	name: "bn4a_branch2b"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res4a_branch2b"
	top: "res4a_branch2b"
	name: "scale4a_branch2b"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	top: "res4a_branch2b"
	bottom: "res4a_branch2b"
	name: "res4a_branch2b_relu"
	type: "ReLU"
}

layer {
	bottom: "res4a_branch2b"
	top: "res4a_branch2c"
	name: "res4a_branch2c"
	type: "Convolution"
	convolution_param {
		num_output: 1024
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4a_branch2c"
	top: "res4a_branch2c"
	name: "bn4a_branch2c"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res4a_branch2c"
	top: "res4a_branch2c"
	name: "scale4a_branch2c"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res4a_branch1"
	bottom: "res4a_branch2c"
	top: "res4a"
	name: "res4a"
	type: "Eltwise"
}

layer {
	bottom: "res4a"
	top: "res4a"
	name: "res4a_relu"
	type: "ReLU"
}

layer {
	bottom: "res4a"
	top: "res4b1_branch2a"
	name: "res4b1_branch2a"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b1_branch2a"
	top: "res4b1_branch2a"
	name: "bn4b1_branch2a"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res4b1_branch2a"
	top: "res4b1_branch2a"
	name: "scale4b1_branch2a"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	top: "res4b1_branch2a"
	bottom: "res4b1_branch2a"
	name: "res4b1_branch2a_relu"
	type: "ReLU"
}

layer {
	bottom: "res4b1_branch2a"
	top: "res4b1_branch2b"
	name: "res4b1_branch2b"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b1_branch2b"
	top: "res4b1_branch2b"
	name: "bn4b1_branch2b"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res4b1_branch2b"
	top: "res4b1_branch2b"
	name: "scale4b1_branch2b"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	top: "res4b1_branch2b"
	bottom: "res4b1_branch2b"
	name: "res4b1_branch2b_relu"
	type: "ReLU"
}

layer {
	bottom: "res4b1_branch2b"
	top: "res4b1_branch2c"
	name: "res4b1_branch2c"
	type: "Convolution"
	convolution_param {
		num_output: 1024
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b1_branch2c"
	top: "res4b1_branch2c"
	name: "bn4b1_branch2c"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res4b1_branch2c"
	top: "res4b1_branch2c"
	name: "scale4b1_branch2c"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res4a"
	bottom: "res4b1_branch2c"
	top: "res4b1"
	name: "res4b1"
	type: "Eltwise"
}

layer {
	bottom: "res4b1"
	top: "res4b1"
	name: "res4b1_relu"
	type: "ReLU"
}

layer {
	bottom: "res4b1"
	top: "res4b2_branch2a"
	name: "res4b2_branch2a"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b2_branch2a"
	top: "res4b2_branch2a"
	name: "bn4b2_branch2a"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res4b2_branch2a"
	top: "res4b2_branch2a"
	name: "scale4b2_branch2a"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	top: "res4b2_branch2a"
	bottom: "res4b2_branch2a"
	name: "res4b2_branch2a_relu"
	type: "ReLU"
}

layer {
	bottom: "res4b2_branch2a"
	top: "res4b2_branch2b"
	name: "res4b2_branch2b"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b2_branch2b"
	top: "res4b2_branch2b"
	name: "bn4b2_branch2b"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res4b2_branch2b"
	top: "res4b2_branch2b"
	name: "scale4b2_branch2b"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	top: "res4b2_branch2b"
	bottom: "res4b2_branch2b"
	name: "res4b2_branch2b_relu"
	type: "ReLU"
}

layer {
	bottom: "res4b2_branch2b"
	top: "res4b2_branch2c"
	name: "res4b2_branch2c"
	type: "Convolution"
	convolution_param {
		num_output: 1024
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b2_branch2c"
	top: "res4b2_branch2c"
	name: "bn4b2_branch2c"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res4b2_branch2c"
	top: "res4b2_branch2c"
	name: "scale4b2_branch2c"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res4b1"
	bottom: "res4b2_branch2c"
	top: "res4b2"
	name: "res4b2"
	type: "Eltwise"
}

layer {
	bottom: "res4b2"
	top: "res4b2"
	name: "res4b2_relu"
	type: "ReLU"
}

layer {
	bottom: "res4b2"
	top: "res4b3_branch2a"
	name: "res4b3_branch2a"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b3_branch2a"
	top: "res4b3_branch2a"
	name: "bn4b3_branch2a"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res4b3_branch2a"
	top: "res4b3_branch2a"
	name: "scale4b3_branch2a"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	top: "res4b3_branch2a"
	bottom: "res4b3_branch2a"
	name: "res4b3_branch2a_relu"
	type: "ReLU"
}

layer {
	bottom: "res4b3_branch2a"
	top: "res4b3_branch2b"
	name: "res4b3_branch2b"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b3_branch2b"
	top: "res4b3_branch2b"
	name: "bn4b3_branch2b"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res4b3_branch2b"
	top: "res4b3_branch2b"
	name: "scale4b3_branch2b"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	top: "res4b3_branch2b"
	bottom: "res4b3_branch2b"
	name: "res4b3_branch2b_relu"
	type: "ReLU"
}

layer {
	bottom: "res4b3_branch2b"
	top: "res4b3_branch2c"
	name: "res4b3_branch2c"
	type: "Convolution"
	convolution_param {
		num_output: 1024
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b3_branch2c"
	top: "res4b3_branch2c"
	name: "bn4b3_branch2c"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res4b3_branch2c"
	top: "res4b3_branch2c"
	name: "scale4b3_branch2c"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res4b2"
	bottom: "res4b3_branch2c"
	top: "res4b3"
	name: "res4b3"
	type: "Eltwise"
}

layer {
	bottom: "res4b3"
	top: "res4b3"
	name: "res4b3_relu"
	type: "ReLU"
}

layer {
	bottom: "res4b3"
	top: "res4b4_branch2a"
	name: "res4b4_branch2a"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b4_branch2a"
	top: "res4b4_branch2a"
	name: "bn4b4_branch2a"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res4b4_branch2a"
	top: "res4b4_branch2a"
	name: "scale4b4_branch2a"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	top: "res4b4_branch2a"
	bottom: "res4b4_branch2a"
	name: "res4b4_branch2a_relu"
	type: "ReLU"
}

layer {
	bottom: "res4b4_branch2a"
	top: "res4b4_branch2b"
	name: "res4b4_branch2b"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b4_branch2b"
	top: "res4b4_branch2b"
	name: "bn4b4_branch2b"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res4b4_branch2b"
	top: "res4b4_branch2b"
	name: "scale4b4_branch2b"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	top: "res4b4_branch2b"
	bottom: "res4b4_branch2b"
	name: "res4b4_branch2b_relu"
	type: "ReLU"
}

layer {
	bottom: "res4b4_branch2b"
	top: "res4b4_branch2c"
	name: "res4b4_branch2c"
	type: "Convolution"
	convolution_param {
		num_output: 1024
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b4_branch2c"
	top: "res4b4_branch2c"
	name: "bn4b4_branch2c"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res4b4_branch2c"
	top: "res4b4_branch2c"
	name: "scale4b4_branch2c"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res4b3"
	bottom: "res4b4_branch2c"
	top: "res4b4"
	name: "res4b4"
	type: "Eltwise"
}

layer {
	bottom: "res4b4"
	top: "res4b4"
	name: "res4b4_relu"
	type: "ReLU"
}

layer {
	bottom: "res4b4"
	top: "res4b5_branch2a"
	name: "res4b5_branch2a"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b5_branch2a"
	top: "res4b5_branch2a"
	name: "bn4b5_branch2a"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res4b5_branch2a"
	top: "res4b5_branch2a"
	name: "scale4b5_branch2a"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	top: "res4b5_branch2a"
	bottom: "res4b5_branch2a"
	name: "res4b5_branch2a_relu"
	type: "ReLU"
}

layer {
	bottom: "res4b5_branch2a"
	top: "res4b5_branch2b"
	name: "res4b5_branch2b"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b5_branch2b"
	top: "res4b5_branch2b"
	name: "bn4b5_branch2b"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res4b5_branch2b"
	top: "res4b5_branch2b"
	name: "scale4b5_branch2b"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	top: "res4b5_branch2b"
	bottom: "res4b5_branch2b"
	name: "res4b5_branch2b_relu"
	type: "ReLU"
}

layer {
	bottom: "res4b5_branch2b"
	top: "res4b5_branch2c"
	name: "res4b5_branch2c"
	type: "Convolution"
	convolution_param {
		num_output: 1024
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b5_branch2c"
	top: "res4b5_branch2c"
	name: "bn4b5_branch2c"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res4b5_branch2c"
	top: "res4b5_branch2c"
	name: "scale4b5_branch2c"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res4b4"
	bottom: "res4b5_branch2c"
	top: "res4b5"
	name: "res4b5"
	type: "Eltwise"
}

layer {
	bottom: "res4b5"
	top: "res4b5"
	name: "res4b5_relu"
	type: "ReLU"
}

layer {
	bottom: "res4b5"
	top: "res4b6_branch2a"
	name: "res4b6_branch2a"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b6_branch2a"
	top: "res4b6_branch2a"
	name: "bn4b6_branch2a"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res4b6_branch2a"
	top: "res4b6_branch2a"
	name: "scale4b6_branch2a"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	top: "res4b6_branch2a"
	bottom: "res4b6_branch2a"
	name: "res4b6_branch2a_relu"
	type: "ReLU"
}

layer {
	bottom: "res4b6_branch2a"
	top: "res4b6_branch2b"
	name: "res4b6_branch2b"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b6_branch2b"
	top: "res4b6_branch2b"
	name: "bn4b6_branch2b"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res4b6_branch2b"
	top: "res4b6_branch2b"
	name: "scale4b6_branch2b"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	top: "res4b6_branch2b"
	bottom: "res4b6_branch2b"
	name: "res4b6_branch2b_relu"
	type: "ReLU"
}

layer {
	bottom: "res4b6_branch2b"
	top: "res4b6_branch2c"
	name: "res4b6_branch2c"
	type: "Convolution"
	convolution_param {
		num_output: 1024
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b6_branch2c"
	top: "res4b6_branch2c"
	name: "bn4b6_branch2c"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res4b6_branch2c"
	top: "res4b6_branch2c"
	name: "scale4b6_branch2c"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res4b5"
	bottom: "res4b6_branch2c"
	top: "res4b6"
	name: "res4b6"
	type: "Eltwise"
}

layer {
	bottom: "res4b6"
	top: "res4b6"
	name: "res4b6_relu"
	type: "ReLU"
}

layer {
	bottom: "res4b6"
	top: "res4b7_branch2a"
	name: "res4b7_branch2a"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b7_branch2a"
	top: "res4b7_branch2a"
	name: "bn4b7_branch2a"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res4b7_branch2a"
	top: "res4b7_branch2a"
	name: "scale4b7_branch2a"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	top: "res4b7_branch2a"
	bottom: "res4b7_branch2a"
	name: "res4b7_branch2a_relu"
	type: "ReLU"
}

layer {
	bottom: "res4b7_branch2a"
	top: "res4b7_branch2b"
	name: "res4b7_branch2b"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b7_branch2b"
	top: "res4b7_branch2b"
	name: "bn4b7_branch2b"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res4b7_branch2b"
	top: "res4b7_branch2b"
	name: "scale4b7_branch2b"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	top: "res4b7_branch2b"
	bottom: "res4b7_branch2b"
	name: "res4b7_branch2b_relu"
	type: "ReLU"
}

layer {
	bottom: "res4b7_branch2b"
	top: "res4b7_branch2c"
	name: "res4b7_branch2c"
	type: "Convolution"
	convolution_param {
		num_output: 1024
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b7_branch2c"
	top: "res4b7_branch2c"
	name: "bn4b7_branch2c"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res4b7_branch2c"
	top: "res4b7_branch2c"
	name: "scale4b7_branch2c"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res4b6"
	bottom: "res4b7_branch2c"
	top: "res4b7"
	name: "res4b7"
	type: "Eltwise"
}

layer {
	bottom: "res4b7"
	top: "res4b7"
	name: "res4b7_relu"
	type: "ReLU"
}

layer {
	bottom: "res4b7"
	top: "res4b8_branch2a"
	name: "res4b8_branch2a"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b8_branch2a"
	top: "res4b8_branch2a"
	name: "bn4b8_branch2a"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res4b8_branch2a"
	top: "res4b8_branch2a"
	name: "scale4b8_branch2a"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	top: "res4b8_branch2a"
	bottom: "res4b8_branch2a"
	name: "res4b8_branch2a_relu"
	type: "ReLU"
}

layer {
	bottom: "res4b8_branch2a"
	top: "res4b8_branch2b"
	name: "res4b8_branch2b"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b8_branch2b"
	top: "res4b8_branch2b"
	name: "bn4b8_branch2b"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res4b8_branch2b"
	top: "res4b8_branch2b"
	name: "scale4b8_branch2b"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	top: "res4b8_branch2b"
	bottom: "res4b8_branch2b"
	name: "res4b8_branch2b_relu"
	type: "ReLU"
}

layer {
	bottom: "res4b8_branch2b"
	top: "res4b8_branch2c"
	name: "res4b8_branch2c"
	type: "Convolution"
	convolution_param {
		num_output: 1024
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b8_branch2c"
	top: "res4b8_branch2c"
	name: "bn4b8_branch2c"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res4b8_branch2c"
	top: "res4b8_branch2c"
	name: "scale4b8_branch2c"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res4b7"
	bottom: "res4b8_branch2c"
	top: "res4b8"
	name: "res4b8"
	type: "Eltwise"
}

layer {
	bottom: "res4b8"
	top: "res4b8"
	name: "res4b8_relu"
	type: "ReLU"
}

layer {
	bottom: "res4b8"
	top: "res4b9_branch2a"
	name: "res4b9_branch2a"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b9_branch2a"
	top: "res4b9_branch2a"
	name: "bn4b9_branch2a"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res4b9_branch2a"
	top: "res4b9_branch2a"
	name: "scale4b9_branch2a"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	top: "res4b9_branch2a"
	bottom: "res4b9_branch2a"
	name: "res4b9_branch2a_relu"
	type: "ReLU"
}

layer {
	bottom: "res4b9_branch2a"
	top: "res4b9_branch2b"
	name: "res4b9_branch2b"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b9_branch2b"
	top: "res4b9_branch2b"
	name: "bn4b9_branch2b"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res4b9_branch2b"
	top: "res4b9_branch2b"
	name: "scale4b9_branch2b"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	top: "res4b9_branch2b"
	bottom: "res4b9_branch2b"
	name: "res4b9_branch2b_relu"
	type: "ReLU"
}

layer {
	bottom: "res4b9_branch2b"
	top: "res4b9_branch2c"
	name: "res4b9_branch2c"
	type: "Convolution"
	convolution_param {
		num_output: 1024
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b9_branch2c"
	top: "res4b9_branch2c"
	name: "bn4b9_branch2c"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res4b9_branch2c"
	top: "res4b9_branch2c"
	name: "scale4b9_branch2c"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res4b8"
	bottom: "res4b9_branch2c"
	top: "res4b9"
	name: "res4b9"
	type: "Eltwise"
}

layer {
	bottom: "res4b9"
	top: "res4b9"
	name: "res4b9_relu"
	type: "ReLU"
}

layer {
	bottom: "res4b9"
	top: "res4b10_branch2a"
	name: "res4b10_branch2a"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b10_branch2a"
	top: "res4b10_branch2a"
	name: "bn4b10_branch2a"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res4b10_branch2a"
	top: "res4b10_branch2a"
	name: "scale4b10_branch2a"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	top: "res4b10_branch2a"
	bottom: "res4b10_branch2a"
	name: "res4b10_branch2a_relu"
	type: "ReLU"
}

layer {
	bottom: "res4b10_branch2a"
	top: "res4b10_branch2b"
	name: "res4b10_branch2b"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b10_branch2b"
	top: "res4b10_branch2b"
	name: "bn4b10_branch2b"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res4b10_branch2b"
	top: "res4b10_branch2b"
	name: "scale4b10_branch2b"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	top: "res4b10_branch2b"
	bottom: "res4b10_branch2b"
	name: "res4b10_branch2b_relu"
	type: "ReLU"
}

layer {
	bottom: "res4b10_branch2b"
	top: "res4b10_branch2c"
	name: "res4b10_branch2c"
	type: "Convolution"
	convolution_param {
		num_output: 1024
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b10_branch2c"
	top: "res4b10_branch2c"
	name: "bn4b10_branch2c"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res4b10_branch2c"
	top: "res4b10_branch2c"
	name: "scale4b10_branch2c"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res4b9"
	bottom: "res4b10_branch2c"
	top: "res4b10"
	name: "res4b10"
	type: "Eltwise"
}

layer {
	bottom: "res4b10"
	top: "res4b10"
	name: "res4b10_relu"
	type: "ReLU"
}

layer {
	bottom: "res4b10"
	top: "res4b11_branch2a"
	name: "res4b11_branch2a"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b11_branch2a"
	top: "res4b11_branch2a"
	name: "bn4b11_branch2a"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res4b11_branch2a"
	top: "res4b11_branch2a"
	name: "scale4b11_branch2a"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	top: "res4b11_branch2a"
	bottom: "res4b11_branch2a"
	name: "res4b11_branch2a_relu"
	type: "ReLU"
}

layer {
	bottom: "res4b11_branch2a"
	top: "res4b11_branch2b"
	name: "res4b11_branch2b"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b11_branch2b"
	top: "res4b11_branch2b"
	name: "bn4b11_branch2b"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res4b11_branch2b"
	top: "res4b11_branch2b"
	name: "scale4b11_branch2b"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	top: "res4b11_branch2b"
	bottom: "res4b11_branch2b"
	name: "res4b11_branch2b_relu"
	type: "ReLU"
}

layer {
	bottom: "res4b11_branch2b"
	top: "res4b11_branch2c"
	name: "res4b11_branch2c"
	type: "Convolution"
	convolution_param {
		num_output: 1024
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b11_branch2c"
	top: "res4b11_branch2c"
	name: "bn4b11_branch2c"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res4b11_branch2c"
	top: "res4b11_branch2c"
	name: "scale4b11_branch2c"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res4b10"
	bottom: "res4b11_branch2c"
	top: "res4b11"
	name: "res4b11"
	type: "Eltwise"
}

layer {
	bottom: "res4b11"
	top: "res4b11"
	name: "res4b11_relu"
	type: "ReLU"
}

layer {
	bottom: "res4b11"
	top: "res4b12_branch2a"
	name: "res4b12_branch2a"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b12_branch2a"
	top: "res4b12_branch2a"
	name: "bn4b12_branch2a"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res4b12_branch2a"
	top: "res4b12_branch2a"
	name: "scale4b12_branch2a"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	top: "res4b12_branch2a"
	bottom: "res4b12_branch2a"
	name: "res4b12_branch2a_relu"
	type: "ReLU"
}

layer {
	bottom: "res4b12_branch2a"
	top: "res4b12_branch2b"
	name: "res4b12_branch2b"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b12_branch2b"
	top: "res4b12_branch2b"
	name: "bn4b12_branch2b"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res4b12_branch2b"
	top: "res4b12_branch2b"
	name: "scale4b12_branch2b"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	top: "res4b12_branch2b"
	bottom: "res4b12_branch2b"
	name: "res4b12_branch2b_relu"
	type: "ReLU"
}

layer {
	bottom: "res4b12_branch2b"
	top: "res4b12_branch2c"
	name: "res4b12_branch2c"
	type: "Convolution"
	convolution_param {
		num_output: 1024
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b12_branch2c"
	top: "res4b12_branch2c"
	name: "bn4b12_branch2c"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res4b12_branch2c"
	top: "res4b12_branch2c"
	name: "scale4b12_branch2c"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res4b11"
	bottom: "res4b12_branch2c"
	top: "res4b12"
	name: "res4b12"
	type: "Eltwise"
}

layer {
	bottom: "res4b12"
	top: "res4b12"
	name: "res4b12_relu"
	type: "ReLU"
}

layer {
	bottom: "res4b12"
	top: "res4b13_branch2a"
	name: "res4b13_branch2a"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b13_branch2a"
	top: "res4b13_branch2a"
	name: "bn4b13_branch2a"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res4b13_branch2a"
	top: "res4b13_branch2a"
	name: "scale4b13_branch2a"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	top: "res4b13_branch2a"
	bottom: "res4b13_branch2a"
	name: "res4b13_branch2a_relu"
	type: "ReLU"
}

layer {
	bottom: "res4b13_branch2a"
	top: "res4b13_branch2b"
	name: "res4b13_branch2b"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b13_branch2b"
	top: "res4b13_branch2b"
	name: "bn4b13_branch2b"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res4b13_branch2b"
	top: "res4b13_branch2b"
	name: "scale4b13_branch2b"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	top: "res4b13_branch2b"
	bottom: "res4b13_branch2b"
	name: "res4b13_branch2b_relu"
	type: "ReLU"
}

layer {
	bottom: "res4b13_branch2b"
	top: "res4b13_branch2c"
	name: "res4b13_branch2c"
	type: "Convolution"
	convolution_param {
		num_output: 1024
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b13_branch2c"
	top: "res4b13_branch2c"
	name: "bn4b13_branch2c"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res4b13_branch2c"
	top: "res4b13_branch2c"
	name: "scale4b13_branch2c"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res4b12"
	bottom: "res4b13_branch2c"
	top: "res4b13"
	name: "res4b13"
	type: "Eltwise"
}

layer {
	bottom: "res4b13"
	top: "res4b13"
	name: "res4b13_relu"
	type: "ReLU"
}

layer {
	bottom: "res4b13"
	top: "res4b14_branch2a"
	name: "res4b14_branch2a"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b14_branch2a"
	top: "res4b14_branch2a"
	name: "bn4b14_branch2a"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res4b14_branch2a"
	top: "res4b14_branch2a"
	name: "scale4b14_branch2a"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	top: "res4b14_branch2a"
	bottom: "res4b14_branch2a"
	name: "res4b14_branch2a_relu"
	type: "ReLU"
}

layer {
	bottom: "res4b14_branch2a"
	top: "res4b14_branch2b"
	name: "res4b14_branch2b"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b14_branch2b"
	top: "res4b14_branch2b"
	name: "bn4b14_branch2b"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res4b14_branch2b"
	top: "res4b14_branch2b"
	name: "scale4b14_branch2b"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	top: "res4b14_branch2b"
	bottom: "res4b14_branch2b"
	name: "res4b14_branch2b_relu"
	type: "ReLU"
}

layer {
	bottom: "res4b14_branch2b"
	top: "res4b14_branch2c"
	name: "res4b14_branch2c"
	type: "Convolution"
	convolution_param {
		num_output: 1024
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b14_branch2c"
	top: "res4b14_branch2c"
	name: "bn4b14_branch2c"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res4b14_branch2c"
	top: "res4b14_branch2c"
	name: "scale4b14_branch2c"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res4b13"
	bottom: "res4b14_branch2c"
	top: "res4b14"
	name: "res4b14"
	type: "Eltwise"
}

layer {
	bottom: "res4b14"
	top: "res4b14"
	name: "res4b14_relu"
	type: "ReLU"
}

layer {
	bottom: "res4b14"
	top: "res4b15_branch2a"
	name: "res4b15_branch2a"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b15_branch2a"
	top: "res4b15_branch2a"
	name: "bn4b15_branch2a"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res4b15_branch2a"
	top: "res4b15_branch2a"
	name: "scale4b15_branch2a"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	top: "res4b15_branch2a"
	bottom: "res4b15_branch2a"
	name: "res4b15_branch2a_relu"
	type: "ReLU"
}

layer {
	bottom: "res4b15_branch2a"
	top: "res4b15_branch2b"
	name: "res4b15_branch2b"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b15_branch2b"
	top: "res4b15_branch2b"
	name: "bn4b15_branch2b"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res4b15_branch2b"
	top: "res4b15_branch2b"
	name: "scale4b15_branch2b"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	top: "res4b15_branch2b"
	bottom: "res4b15_branch2b"
	name: "res4b15_branch2b_relu"
	type: "ReLU"
}

layer {
	bottom: "res4b15_branch2b"
	top: "res4b15_branch2c"
	name: "res4b15_branch2c"
	type: "Convolution"
	convolution_param {
		num_output: 1024
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b15_branch2c"
	top: "res4b15_branch2c"
	name: "bn4b15_branch2c"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res4b15_branch2c"
	top: "res4b15_branch2c"
	name: "scale4b15_branch2c"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res4b14"
	bottom: "res4b15_branch2c"
	top: "res4b15"
	name: "res4b15"
	type: "Eltwise"
}

layer {
	bottom: "res4b15"
	top: "res4b15"
	name: "res4b15_relu"
	type: "ReLU"
}

layer {
	bottom: "res4b15"
	top: "res4b16_branch2a"
	name: "res4b16_branch2a"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b16_branch2a"
	top: "res4b16_branch2a"
	name: "bn4b16_branch2a"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res4b16_branch2a"
	top: "res4b16_branch2a"
	name: "scale4b16_branch2a"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	top: "res4b16_branch2a"
	bottom: "res4b16_branch2a"
	name: "res4b16_branch2a_relu"
	type: "ReLU"
}

layer {
	bottom: "res4b16_branch2a"
	top: "res4b16_branch2b"
	name: "res4b16_branch2b"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b16_branch2b"
	top: "res4b16_branch2b"
	name: "bn4b16_branch2b"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res4b16_branch2b"
	top: "res4b16_branch2b"
	name: "scale4b16_branch2b"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	top: "res4b16_branch2b"
	bottom: "res4b16_branch2b"
	name: "res4b16_branch2b_relu"
	type: "ReLU"
}

layer {
	bottom: "res4b16_branch2b"
	top: "res4b16_branch2c"
	name: "res4b16_branch2c"
	type: "Convolution"
	convolution_param {
		num_output: 1024
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b16_branch2c"
	top: "res4b16_branch2c"
	name: "bn4b16_branch2c"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res4b16_branch2c"
	top: "res4b16_branch2c"
	name: "scale4b16_branch2c"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res4b15"
	bottom: "res4b16_branch2c"
	top: "res4b16"
	name: "res4b16"
	type: "Eltwise"
}

layer {
	bottom: "res4b16"
	top: "res4b16"
	name: "res4b16_relu"
	type: "ReLU"
}

layer {
	bottom: "res4b16"
	top: "res4b17_branch2a"
	name: "res4b17_branch2a"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b17_branch2a"
	top: "res4b17_branch2a"
	name: "bn4b17_branch2a"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res4b17_branch2a"
	top: "res4b17_branch2a"
	name: "scale4b17_branch2a"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	top: "res4b17_branch2a"
	bottom: "res4b17_branch2a"
	name: "res4b17_branch2a_relu"
	type: "ReLU"
}

layer {
	bottom: "res4b17_branch2a"
	top: "res4b17_branch2b"
	name: "res4b17_branch2b"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b17_branch2b"
	top: "res4b17_branch2b"
	name: "bn4b17_branch2b"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res4b17_branch2b"
	top: "res4b17_branch2b"
	name: "scale4b17_branch2b"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	top: "res4b17_branch2b"
	bottom: "res4b17_branch2b"
	name: "res4b17_branch2b_relu"
	type: "ReLU"
}

layer {
	bottom: "res4b17_branch2b"
	top: "res4b17_branch2c"
	name: "res4b17_branch2c"
	type: "Convolution"
	convolution_param {
		num_output: 1024
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b17_branch2c"
	top: "res4b17_branch2c"
	name: "bn4b17_branch2c"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res4b17_branch2c"
	top: "res4b17_branch2c"
	name: "scale4b17_branch2c"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res4b16"
	bottom: "res4b17_branch2c"
	top: "res4b17"
	name: "res4b17"
	type: "Eltwise"
}

layer {
	bottom: "res4b17"
	top: "res4b17"
	name: "res4b17_relu"
	type: "ReLU"
}

layer {
	bottom: "res4b17"
	top: "res4b18_branch2a"
	name: "res4b18_branch2a"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b18_branch2a"
	top: "res4b18_branch2a"
	name: "bn4b18_branch2a"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res4b18_branch2a"
	top: "res4b18_branch2a"
	name: "scale4b18_branch2a"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	top: "res4b18_branch2a"
	bottom: "res4b18_branch2a"
	name: "res4b18_branch2a_relu"
	type: "ReLU"
}

layer {
	bottom: "res4b18_branch2a"
	top: "res4b18_branch2b"
	name: "res4b18_branch2b"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b18_branch2b"
	top: "res4b18_branch2b"
	name: "bn4b18_branch2b"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res4b18_branch2b"
	top: "res4b18_branch2b"
	name: "scale4b18_branch2b"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	top: "res4b18_branch2b"
	bottom: "res4b18_branch2b"
	name: "res4b18_branch2b_relu"
	type: "ReLU"
}

layer {
	bottom: "res4b18_branch2b"
	top: "res4b18_branch2c"
	name: "res4b18_branch2c"
	type: "Convolution"
	convolution_param {
		num_output: 1024
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b18_branch2c"
	top: "res4b18_branch2c"
	name: "bn4b18_branch2c"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res4b18_branch2c"
	top: "res4b18_branch2c"
	name: "scale4b18_branch2c"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res4b17"
	bottom: "res4b18_branch2c"
	top: "res4b18"
	name: "res4b18"
	type: "Eltwise"
}

layer {
	bottom: "res4b18"
	top: "res4b18"
	name: "res4b18_relu"
	type: "ReLU"
}

layer {
	bottom: "res4b18"
	top: "res4b19_branch2a"
	name: "res4b19_branch2a"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b19_branch2a"
	top: "res4b19_branch2a"
	name: "bn4b19_branch2a"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res4b19_branch2a"
	top: "res4b19_branch2a"
	name: "scale4b19_branch2a"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	top: "res4b19_branch2a"
	bottom: "res4b19_branch2a"
	name: "res4b19_branch2a_relu"
	type: "ReLU"
}

layer {
	bottom: "res4b19_branch2a"
	top: "res4b19_branch2b"
	name: "res4b19_branch2b"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b19_branch2b"
	top: "res4b19_branch2b"
	name: "bn4b19_branch2b"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res4b19_branch2b"
	top: "res4b19_branch2b"
	name: "scale4b19_branch2b"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	top: "res4b19_branch2b"
	bottom: "res4b19_branch2b"
	name: "res4b19_branch2b_relu"
	type: "ReLU"
}

layer {
	bottom: "res4b19_branch2b"
	top: "res4b19_branch2c"
	name: "res4b19_branch2c"
	type: "Convolution"
	convolution_param {
		num_output: 1024
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b19_branch2c"
	top: "res4b19_branch2c"
	name: "bn4b19_branch2c"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res4b19_branch2c"
	top: "res4b19_branch2c"
	name: "scale4b19_branch2c"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res4b18"
	bottom: "res4b19_branch2c"
	top: "res4b19"
	name: "res4b19"
	type: "Eltwise"
}

layer {
	bottom: "res4b19"
	top: "res4b19"
	name: "res4b19_relu"
	type: "ReLU"
}

layer {
	bottom: "res4b19"
	top: "res4b20_branch2a"
	name: "res4b20_branch2a"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b20_branch2a"
	top: "res4b20_branch2a"
	name: "bn4b20_branch2a"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res4b20_branch2a"
	top: "res4b20_branch2a"
	name: "scale4b20_branch2a"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	top: "res4b20_branch2a"
	bottom: "res4b20_branch2a"
	name: "res4b20_branch2a_relu"
	type: "ReLU"
}

layer {
	bottom: "res4b20_branch2a"
	top: "res4b20_branch2b"
	name: "res4b20_branch2b"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b20_branch2b"
	top: "res4b20_branch2b"
	name: "bn4b20_branch2b"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res4b20_branch2b"
	top: "res4b20_branch2b"
	name: "scale4b20_branch2b"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	top: "res4b20_branch2b"
	bottom: "res4b20_branch2b"
	name: "res4b20_branch2b_relu"
	type: "ReLU"
}

layer {
	bottom: "res4b20_branch2b"
	top: "res4b20_branch2c"
	name: "res4b20_branch2c"
	type: "Convolution"
	convolution_param {
		num_output: 1024
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b20_branch2c"
	top: "res4b20_branch2c"
	name: "bn4b20_branch2c"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res4b20_branch2c"
	top: "res4b20_branch2c"
	name: "scale4b20_branch2c"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res4b19"
	bottom: "res4b20_branch2c"
	top: "res4b20"
	name: "res4b20"
	type: "Eltwise"
}

layer {
	bottom: "res4b20"
	top: "res4b20"
	name: "res4b20_relu"
	type: "ReLU"
}

layer {
	bottom: "res4b20"
	top: "res4b21_branch2a"
	name: "res4b21_branch2a"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b21_branch2a"
	top: "res4b21_branch2a"
	name: "bn4b21_branch2a"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res4b21_branch2a"
	top: "res4b21_branch2a"
	name: "scale4b21_branch2a"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	top: "res4b21_branch2a"
	bottom: "res4b21_branch2a"
	name: "res4b21_branch2a_relu"
	type: "ReLU"
}

layer {
	bottom: "res4b21_branch2a"
	top: "res4b21_branch2b"
	name: "res4b21_branch2b"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b21_branch2b"
	top: "res4b21_branch2b"
	name: "bn4b21_branch2b"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res4b21_branch2b"
	top: "res4b21_branch2b"
	name: "scale4b21_branch2b"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	top: "res4b21_branch2b"
	bottom: "res4b21_branch2b"
	name: "res4b21_branch2b_relu"
	type: "ReLU"
}

layer {
	bottom: "res4b21_branch2b"
	top: "res4b21_branch2c"
	name: "res4b21_branch2c"
	type: "Convolution"
	convolution_param {
		num_output: 1024
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b21_branch2c"
	top: "res4b21_branch2c"
	name: "bn4b21_branch2c"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res4b21_branch2c"
	top: "res4b21_branch2c"
	name: "scale4b21_branch2c"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res4b20"
	bottom: "res4b21_branch2c"
	top: "res4b21"
	name: "res4b21"
	type: "Eltwise"
}

layer {
	bottom: "res4b21"
	top: "res4b21"
	name: "res4b21_relu"
	type: "ReLU"
}

layer {
	bottom: "res4b21"
	top: "res4b22_branch2a"
	name: "res4b22_branch2a"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b22_branch2a"
	top: "res4b22_branch2a"
	name: "bn4b22_branch2a"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res4b22_branch2a"
	top: "res4b22_branch2a"
	name: "scale4b22_branch2a"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	top: "res4b22_branch2a"
	bottom: "res4b22_branch2a"
	name: "res4b22_branch2a_relu"
	type: "ReLU"
}

layer {
	bottom: "res4b22_branch2a"
	top: "res4b22_branch2b"
	name: "res4b22_branch2b"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b22_branch2b"
	top: "res4b22_branch2b"
	name: "bn4b22_branch2b"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res4b22_branch2b"
	top: "res4b22_branch2b"
	name: "scale4b22_branch2b"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	top: "res4b22_branch2b"
	bottom: "res4b22_branch2b"
	name: "res4b22_branch2b_relu"
	type: "ReLU"
}

layer {
	bottom: "res4b22_branch2b"
	top: "res4b22_branch2c"
	name: "res4b22_branch2c"
	type: "Convolution"
	convolution_param {
		num_output: 1024
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b22_branch2c"
	top: "res4b22_branch2c"
	name: "bn4b22_branch2c"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res4b22_branch2c"
	top: "res4b22_branch2c"
	name: "scale4b22_branch2c"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res4b21"
	bottom: "res4b22_branch2c"
	top: "res4b22"
	name: "res4b22"
	type: "Eltwise"
}

layer {
	bottom: "res4b22"
	top: "res4b22"
	name: "res4b22_relu"
	type: "ReLU"
}

layer {
	bottom: "res4b22"
	top: "res5a_branch1"
	name: "res5a_branch1"
	type: "Convolution"
	convolution_param {
		num_output: 2048
		kernel_size: 1
		pad: 0
		stride: 2
		bias_term: false
	}
}

layer {
	bottom: "res5a_branch1"
	top: "res5a_branch1"
	name: "bn5a_branch1"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res5a_branch1"
	top: "res5a_branch1"
	name: "scale5a_branch1"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res4b22"
	top: "res5a_branch2a"
	name: "res5a_branch2a"
	type: "Convolution"
	convolution_param {
		num_output: 512
		kernel_size: 1
		pad: 0
		stride: 2
		bias_term: false
	}
}

layer {
	bottom: "res5a_branch2a"
	top: "res5a_branch2a"
	name: "bn5a_branch2a"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res5a_branch2a"
	top: "res5a_branch2a"
	name: "scale5a_branch2a"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	top: "res5a_branch2a"
	bottom: "res5a_branch2a"
	name: "res5a_branch2a_relu"
	type: "ReLU"
}

layer {
	bottom: "res5a_branch2a"
	top: "res5a_branch2b"
	name: "res5a_branch2b"
	type: "Convolution"
	convolution_param {
		num_output: 512
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res5a_branch2b"
	top: "res5a_branch2b"
	name: "bn5a_branch2b"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res5a_branch2b"
	top: "res5a_branch2b"
	name: "scale5a_branch2b"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	top: "res5a_branch2b"
	bottom: "res5a_branch2b"
	name: "res5a_branch2b_relu"
	type: "ReLU"
}

layer {
	bottom: "res5a_branch2b"
	top: "res5a_branch2c"
	name: "res5a_branch2c"
	type: "Convolution"
	convolution_param {
		num_output: 2048
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res5a_branch2c"
	top: "res5a_branch2c"
	name: "bn5a_branch2c"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res5a_branch2c"
	top: "res5a_branch2c"
	name: "scale5a_branch2c"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res5a_branch1"
	bottom: "res5a_branch2c"
	top: "res5a"
	name: "res5a"
	type: "Eltwise"
}

layer {
	bottom: "res5a"
	top: "res5a"
	name: "res5a_relu"
	type: "ReLU"
}

layer {
	bottom: "res5a"
	top: "res5b_branch2a"
	name: "res5b_branch2a"
	type: "Convolution"
	convolution_param {
		num_output: 512
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res5b_branch2a"
	top: "res5b_branch2a"
	name: "bn5b_branch2a"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res5b_branch2a"
	top: "res5b_branch2a"
	name: "scale5b_branch2a"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	top: "res5b_branch2a"
	bottom: "res5b_branch2a"
	name: "res5b_branch2a_relu"
	type: "ReLU"
}

layer {
	bottom: "res5b_branch2a"
	top: "res5b_branch2b"
	name: "res5b_branch2b"
	type: "Convolution"
	convolution_param {
		num_output: 512
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res5b_branch2b"
	top: "res5b_branch2b"
	name: "bn5b_branch2b"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res5b_branch2b"
	top: "res5b_branch2b"
	name: "scale5b_branch2b"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	top: "res5b_branch2b"
	bottom: "res5b_branch2b"
	name: "res5b_branch2b_relu"
	type: "ReLU"
}

layer {
	bottom: "res5b_branch2b"
	top: "res5b_branch2c"
	name: "res5b_branch2c"
	type: "Convolution"
	convolution_param {
		num_output: 2048
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res5b_branch2c"
	top: "res5b_branch2c"
	name: "bn5b_branch2c"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res5b_branch2c"
	top: "res5b_branch2c"
	name: "scale5b_branch2c"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res5a"
	bottom: "res5b_branch2c"
	top: "res5b"
	name: "res5b"
	type: "Eltwise"
}

layer {
	bottom: "res5b"
	top: "res5b"
	name: "res5b_relu"
	type: "ReLU"
}

layer {
	bottom: "res5b"
	top: "res5c_branch2a"
	name: "res5c_branch2a"
	type: "Convolution"
	convolution_param {
		num_output: 512
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res5c_branch2a"
	top: "res5c_branch2a"
	name: "bn5c_branch2a"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res5c_branch2a"
	top: "res5c_branch2a"
	name: "scale5c_branch2a"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	top: "res5c_branch2a"
	bottom: "res5c_branch2a"
	name: "res5c_branch2a_relu"
	type: "ReLU"
}

layer {
	bottom: "res5c_branch2a"
	top: "res5c_branch2b"
	name: "res5c_branch2b"
	type: "Convolution"
	convolution_param {
		num_output: 512
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res5c_branch2b"
	top: "res5c_branch2b"
	name: "bn5c_branch2b"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res5c_branch2b"
	top: "res5c_branch2b"
	name: "scale5c_branch2b"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	top: "res5c_branch2b"
	bottom: "res5c_branch2b"
	name: "res5c_branch2b_relu"
	type: "ReLU"
}

layer {
	bottom: "res5c_branch2b"
	top: "res5c_branch2c"
	name: "res5c_branch2c"
	type: "Convolution"
	convolution_param {
		num_output: 2048
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res5c_branch2c"
	top: "res5c_branch2c"
	name: "bn5c_branch2c"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res5c_branch2c"
	top: "res5c_branch2c"
	name: "scale5c_branch2c"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res5b"
	bottom: "res5c_branch2c"
	top: "res5c"
	name: "res5c"
	type: "Eltwise"
}

layer {
	bottom: "res5c"
	top: "res5c"
	name: "res5c_relu"
	type: "ReLU"
}
####################################################### FPN
layer {
	bottom: "res5c"
	top: "p5"
	name: "c5"
	param {
		lr_mult: 1.0
	}
	param {
		lr_mult: 2.0
	}
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 1
                weight_filler {
                    type: "msra"
                }
                bias_filler {
                    type: "constant"
                    value: 0
                }
	}
}

layer {
	top: "p5"
	bottom: "p5"
	name: "p5_relu"
	type: "ReLU"
}

layer {
	bottom: "res4b22"
	top: "c4"
	name: "newC4"
	param {
		lr_mult: 1.0
	}
	param {
		lr_mult: 2.0
	}
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 1
                weight_filler {
                    type: "msra"
                }
                bias_filler {
                    type: "constant"
                    value: 0
                }
        
	}
}

layer {
	top: "c4"
	bottom: "c4"
	name: "c4_relu"
	type: "ReLU"
}

layer {
   name: "up_p5"
   type: "InterpAdvance"
   bottom: "p5"
   bottom: "c4"
   top: "c_up_p5"
}

layer {
    name: "sum4"
    type: "Eltwise"
    bottom: "c4"
    bottom: "c_up_p5"
    top: "sum4"
    eltwise_param {
        operation: SUM
    }
}


layer {
	bottom: "sum4"
	top: "p4"
	name: "p4"
	param {
		lr_mult: 1.0
	}
	param {
		lr_mult: 2.0
	}
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 3
                pad: 1
		stride: 1
                weight_filler {
                    type: "msra"
                }
                bias_filler {
                    type: "constant"
                    value: 0
                }
        
	}
}

layer {
	top: "p4"
	bottom: "p4"
	name: "p4_relu"
	type: "ReLU"
}

layer {
	bottom: "res3b3"
	top: "c3"
	name: "newC3"
	param {
		lr_mult: 1.0
	}
	param {
		lr_mult: 2.0
	}
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 1
                weight_filler {
                    type: "msra"
                }
                bias_filler {
                    type: "constant"
                    value: 0
                }
        
	}
}

layer {
	top: "c3"
	bottom: "c3"
	name: "c3_relu"
	type: "ReLU"
}

layer {
   name: "up_p4"
   type: "InterpAdvance"
   bottom: "p4"
   bottom: "c3"
   top: "c_up_p4"
}


layer {
    name: "sum3"
    type: "Eltwise"
    bottom: "c3"
    bottom: "c_up_p4"
    top: "sum3"
    eltwise_param {
        operation: SUM
    }
}


layer {
	bottom: "sum3"
	top: "p3"
	name: "p3"
	param {
		lr_mult: 1.0
	}
	param {
		lr_mult: 2.0
	}
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 3
                pad: 1
		stride: 1
                weight_filler {
                    type: "msra"
                }
                bias_filler {
                    type: "constant"
                    value: 0
                }
        
	}
}

layer {
	top: "p3"
	bottom: "p3"
	name: "p3_relu"
	type: "ReLU"
}

layer {
	bottom: "res2c"
	top: "c2"
	name: "newC2"
	param {
		lr_mult: 1.0
	}
	param {
		lr_mult: 2.0
	}
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 1
                weight_filler {
                    type: "msra"
                }
                bias_filler {
                    type: "constant"
                    value: 0
                }
        
	}
}

layer {
	top: "c2"
	bottom: "c2"
	name: "c2_relu"
	type: "ReLU"
}

layer {
   name: "up_p3"
   type: "InterpAdvance"
   bottom: "p3"
   bottom: "c2"
   top: "c_up_p3"
}


layer {
    name: "sum2"
    type: "Eltwise"
    bottom: "c2"
    bottom: "c_up_p3"
    top: "sum2"
    eltwise_param {
        operation: SUM
    }
}

layer {
	bottom: "sum2"
	top: "p2"
	name: "p2"
	param {
		lr_mult: 1.0
	}
	param {
		lr_mult: 2.0
	}
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 3
                pad: 1
		stride: 1
                weight_filler {
                    type: "msra"
                }
                bias_filler {
                    type: "constant"
                    value: 0
                }
        
	}
}

layer {
	top: "p2"
	bottom: "p2"
	name: "p2_relu"
	type: "ReLU"
}

##################################### non-local feature 5
layer {
  name: "conv_theta5"
  type: "Convolution"
  bottom: "p5"
  top: "conv_theta5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_term: false
  }
}

layer {
  name: "conv_fi5"
  type: "Convolution"
  bottom: "p5"
  top: "conv_fi5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_term: false
  }
}

layer {
  name: "conv_g5"
  type: "Convolution"
  bottom: "p5"
  top: "conv_g5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_term: false
  }
}

layer {
    name: "conv_theta5_r1"
    type: "Reshape"
    bottom: "conv_theta5"
    top: "conv_theta5_r1"
    reshape_param {
      shape {
        dim: 0  # copy the dimension from below
        dim: 0
        dim: -1
        # dim: 1
      }
    }
}

layer {
    name: "conv_fi5_r1"
    type: "Reshape"
    bottom: "conv_fi5"
    top: "conv_fi5_r1"
    reshape_param {
      shape {
        dim: 0  # copy the dimension from below
        dim: 0
        dim: -1
        # dim: 1
      }
    }
}

layer {
    name: "conv_g5_r1"
    type: "Reshape"
    bottom: "conv_g5"
    top: "conv_g5_r1"
    reshape_param {
      shape {
        dim: 0  # copy the dimension from below
        dim: 0
        dim: -1
        # dim: 1
      }
    }
}

layer {
   name: "conv_theta5_t1"
   type: "MatrixTransposition"
   bottom: "conv_theta5_r1"
   top: "conv_theta5_t1"
}

layer {
   name: "matrix5_mul1"
   type: "MatrixMultiplication"
   bottom: "conv_theta5_t1"
   bottom: "conv_fi5_r1"
   top: "5mm1"
}


layer {
  name: "softmax5_mm1"
  type: "Softmax"
  bottom: "5mm1"
  top: "5mm1"
  softmax_param {
     axis: 2 #(n,c,w,h) w
  }
}

layer {
   name: "matrix5_mul2"
   type: "MatrixMultiplicationYt"
   bottom: "5mm1"
   bottom: "conv_g5_r1"
   top: "5mm2"
}


layer {
   name: "nonlocal5_r"
   type: "MatrixTransposition"
   bottom: "5mm2"
   top: "nonlocal5_r"
}


layer {
    name: "nonlocal5_temp"
    type: "ReshapeAdvance"
    bottom: "nonlocal5_r"
    bottom: "conv_theta5"
    top: "nonlocal5_temp"
    reshape_param {
      shape {
        dim: 0  # copy the dimension from below
        dim: 0
        dim: -1 # infer it from the other dimensions
        dim: -2 # refer to the bottom[1]
      }
    }
}

layer {
  name: "nonlocal5_conv"
  type: "Convolution"
  bottom: "nonlocal5_temp"
  top: "nonlocal5_conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_term: false
  }
}

layer {
	bottom: "p5"
	bottom: "nonlocal5_conv"
	top: "feature55"
	name: "feature55"
	type: "Eltwise"
}

layer {
  name: "feature5"
  type: "Convolution"
  bottom: "feature55"
  top: "feature5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    kernel_size: 3
    pad: 1
    stride: 1
    weight_filler {
        type: "msra"
    }
    bias_filler {
        type: "constant"
        value: 0
    }
  }
}

##################################### predict 5
layer {
  name: "predict5"
  type: "Convolution"
  bottom: "feature5"
  top: "predict5"
  param {
    lr_mult: 0.1
    decay_mult: 1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  convolution_param {
    num_output: 1
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CAFFE
  }
}


layer {
   name: "upsample16_in_dsn5"
   type: "InterpAdvance"
   bottom: "predict5"
   bottom: "data"
   top: "up_predict5"
}

layer {
  name: "loss5"
  type: "SigmoidCrossEntropyLoss"
  bottom: "up_predict5"
  bottom: "label"
  top: "loss5"
  loss_weight: 1
  include {
    phase: TRAIN
  }
}
layer {
  name: "sigmoid5"
  type: "Sigmoid"
  bottom: "up_predict5"
  top: "sigmoid5"
  include {
    phase: TEST
  }
}


##################################### non-local feature 4
layer {
  name: "conv_theta4"
  type: "Convolution"
  bottom: "p4"
  top: "conv_theta4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_term: false
  }
}

layer {
  name: "conv_fi4"
  type: "Convolution"
  bottom: "p4"
  top: "conv_fi4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_term: false
  }
}

layer {
  name: "conv_g4"
  type: "Convolution"
  bottom: "p4"
  top: "conv_g4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_term: false
  }
}

layer {
    name: "conv_theta4_r1"
    type: "Reshape"
    bottom: "conv_theta4"
    top: "conv_theta4_r1"
    reshape_param {
      shape {
        dim: 0  # copy the dimension from below
        dim: 0
        dim: -1
        # dim: 1
      }
    }
}

layer {
    name: "conv_fi4_r1"
    type: "Reshape"
    bottom: "conv_fi4"
    top: "conv_fi4_r1"
    reshape_param {
      shape {
        dim: 0  # copy the dimension from below
        dim: 0
        dim: -1
        # dim: 1
      }
    }
}

layer {
    name: "conv_g4_r1"
    type: "Reshape"
    bottom: "conv_g4"
    top: "conv_g4_r1"
    reshape_param {
      shape {
        dim: 0  # copy the dimension from below
        dim: 0
        dim: -1
        # dim: 1
      }
    }
}

layer {
   name: "conv_theta4_t1"
   type: "MatrixTransposition"
   bottom: "conv_theta4_r1"
   top: "conv_theta4_t1"
}

layer {
   name: "matrix4_mul1"
   type: "MatrixMultiplication"
   bottom: "conv_theta4_t1"
   bottom: "conv_fi4_r1"
   top: "4mm1"
}


layer {
  name: "softmax4_mm1"
  type: "Softmax"
  bottom: "4mm1"
  top: "4mm1"
  softmax_param {
     axis: 2 #(n,c,w,h) w
  }
}


######## guidence of the last predicted map
layer {
   name: "resize5_to4"
   type: "InterpAdvance"
   bottom: "up_predict5"
   bottom: "conv_theta4"
   top: "s5to4"
}

layer {
    name: "reshape_s5to4"
    type: "Reshape"
    bottom: "s5to4"
    top: "s5to4_r"
    reshape_param {
      shape {
        dim: 0  # copy the dimension from below
        dim: 0
        dim: -1
        # dim: 1
      }
    }
}


layer {
   name: "s5to4_r_t"
   type: "MatrixTransposition"
   bottom: "s5to4_r"
   top: "s5to4_r_t"
}

layer {
   name: "s5to4_mul1"
   type: "MatrixMultiplication"
   bottom: "s5to4_r_t"
   bottom: "s5to4_r"
   top: "45mm1"
}


layer {
  name: "softmax_45mm1"
  type: "Softmax"
  bottom: "45mm1"
  top: "45mm1"
  softmax_param {
     axis: 2 #(n,c,w,h) w
  }
}


layer {
   name: "matrix45_mul1"
   type: "MatrixMultiplication"
   bottom: "4mm1"
   bottom: "45mm1"
   top: "final_4mm1"
}


layer {
  name: "softmax_final_4mm1"
  type: "Softmax"
  bottom: "final_4mm1"
  top: "final_4mm1"
  softmax_param {
     axis: 2 #(n,c,w,h) w
  }
}


layer {
   name: "matrix4_mul2"
   type: "MatrixMultiplicationYt"
   bottom: "final_4mm1"
   bottom: "conv_g4_r1"
   top: "4mm2"
}


layer {
   name: "nonlocal4_r"
   type: "MatrixTransposition"
   bottom: "4mm2"
   top: "nonlocal4_r"
}


layer {
    name: "nonlocal4_temp"
    type: "ReshapeAdvance"
    bottom: "nonlocal4_r"
    bottom: "conv_theta4"
    top: "nonlocal4_temp"
    reshape_param {
      shape {
        dim: 0  # copy the dimension from below
        dim: 0
        dim: -1 # infer it from the other dimensions
        dim: -2 # refer to the bottom[1]
      }
    }
}

layer {
  name: "nonlocal4_conv"
  type: "Convolution"
  bottom: "nonlocal4_temp"
  top: "nonlocal4_conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_term: false
  }
}


layer {
	bottom: "p4"
	bottom: "nonlocal4_conv"
	top: "feature4_temp"
	name: "feature4_temp"
	type: "Eltwise"
}

layer {
  name: "feature4_conv"
  type: "Convolution"
  bottom: "feature4_temp"
  top: "feature4_conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    kernel_size: 3
    pad: 1
    stride: 1
    weight_filler {
        type: "msra"
    }
    bias_filler {
        type: "constant"
        value: 0
    }
  }
}

layer {
   name: "feature5_to4"
   type: "InterpAdvance"
   bottom: "feature5"
   bottom: "feature4_conv"
   top: "feature5_to4"
}

layer {
	bottom: "feature4_conv"
	bottom: "feature5_to4"
	top: "feature45"
	name: "feature45"
	type: "Eltwise"
}

layer {
  name: "feature4"
  type: "Convolution"
  bottom: "feature45"
  top: "feature4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    kernel_size: 3
    pad: 1
    stride: 1
    weight_filler {
        type: "msra"
    }
    bias_filler {
        type: "constant"
        value: 0
    }
  }
}

##################################### predict 4
layer {
  name: "predict4"
  type: "Convolution"
  bottom: "feature4"
  top: "predict4"
  param {
    lr_mult: 0.1
    decay_mult: 1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  convolution_param {
    num_output: 1
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CAFFE
  }
}



layer {
   name: "upsample8_in_dsn4"
   type: "InterpAdvance"
   bottom: "predict4"
   bottom: "data"
   top: "up_predict4"
}

layer {
	bottom: "up_predict4"
	bottom: "up_predict5"
	top: "final_predict4"
	name: "final_predict4"
	type: "Eltwise"
}

layer {
  name: "loss4"
  type: "SigmoidCrossEntropyLoss"
  bottom: "final_predict4"
  bottom: "label"
  top: "loss4"
  loss_weight: 1
  include {
    phase: TRAIN
  }
}
layer {
  name: "sigmoid4"
  type: "Sigmoid"
  bottom: "final_predict4"
  top: "sigmoid4"
  include {
    phase: TEST
  }
}


##################################### non-local feature 3
#layer {
#  name: "pool1_p3"
#  type: "Pooling"
#  bottom: "p3"
#  top: "pool1_p3"
#  pooling_param {
#    pool: AVE
#    kernel_size: 2
#    stride: 2
#  }
#}


layer {
  name: "conv_theta3"
  type: "Convolution"
  bottom: "p3"
  top: "conv_theta3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_term: false
  }
}

layer {
  name: "conv_fi3"
  type: "Convolution"
  bottom: "p3"
  top: "conv_fi3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_term: false
  }
}

layer {
  name: "conv_g3"
  type: "Convolution"
  bottom: "p3"
  top: "conv_g3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_term: false
  }
}

layer {
    name: "conv_theta3_r1"
    type: "Reshape"
    bottom: "conv_theta3"
    top: "conv_theta3_r1"
    reshape_param {
      shape {
        dim: 0  # copy the dimension from below
        dim: 0
        dim: -1
        # dim: 1
      }
    }
}

layer {
    name: "conv_fi3_r1"
    type: "Reshape"
    bottom: "conv_fi3"
    top: "conv_fi3_r1"
    reshape_param {
      shape {
        dim: 0  # copy the dimension from below
        dim: 0
        dim: -1
        # dim: 1
      }
    }
}

layer {
    name: "conv_g3_r1"
    type: "Reshape"
    bottom: "conv_g3"
    top: "conv_g3_r1"
    reshape_param {
      shape {
        dim: 0  # copy the dimension from below
        dim: 0
        dim: -1
        # dim: 1
      }
    }
}

layer {
   name: "conv_theta3_t1"
   type: "MatrixTransposition"
   bottom: "conv_theta3_r1"
   top: "conv_theta3_t1"
}

layer {
   name: "matrix3_mul1"
   type: "MatrixMultiplication"
   bottom: "conv_theta3_t1"
   bottom: "conv_fi3_r1"
   top: "3mm1"
}


layer {
  name: "softmax3_mm1"
  type: "Softmax"
  bottom: "3mm1"
  top: "3mm1"
  softmax_param {
     axis: 2 #(n,c,w,h) w
  }
}


######## guidence of the last predicted map
layer {
   name: "resize4_to3"
   type: "InterpAdvance"
   bottom: "final_predict4"
   bottom: "conv_theta3"
   top: "s4to3"
}

layer {
    name: "reshape_s4to3"
    type: "Reshape"
    bottom: "s4to3"
    top: "s4to3_r"
    reshape_param {
      shape {
        dim: 0  # copy the dimension from below
        dim: 0
        dim: -1
        # dim: 1
      }
    }
}


layer {
   name: "s4to3_r_t"
   type: "MatrixTransposition"
   bottom: "s4to3_r"
   top: "s4to3_r_t"
}

layer {
   name: "s4to3_mul1"
   type: "MatrixMultiplication"
   bottom: "s4to3_r_t"
   bottom: "s4to3_r"
   top: "34mm1"
}


layer {
  name: "softmax_34mm1"
  type: "Softmax"
  bottom: "34mm1"
  top: "34mm1"
  softmax_param {
     axis: 2 #(n,c,w,h) w
  }
}

layer {
   name: "matrix34_mul1"
   type: "MatrixMultiplication"
   bottom: "3mm1"
   bottom: "34mm1"
   top: "final_3mm1"
}


layer {
  name: "softmax_final_3mm1"
  type: "Softmax"
  bottom: "final_3mm1"
  top: "final_3mm1"
  softmax_param {
     axis: 2 #(n,c,w,h) w
  }
}


layer {
   name: "matrix3_mul2"
   type: "MatrixMultiplicationYt"
   bottom: "final_3mm1"
   bottom: "conv_g3_r1"
   top: "3mm2"
}


layer {
   name: "nonlocal3_r"
   type: "MatrixTransposition"
   bottom: "3mm2"
   top: "nonlocal3_r"
}


layer {
    name: "nonlocal3_temp"
    type: "ReshapeAdvance"
    bottom: "nonlocal3_r"
    bottom: "conv_theta3"
    top: "nonlocal3_temp"
    reshape_param {
      shape {
        dim: 0  # copy the dimension from below
        dim: 0
        dim: -1 # infer it from the other dimensions
        dim: -2 # refer to the bottom[1]
      }
    }
}

layer {
  name: "nonlocal3_conv"
  type: "Convolution"
  bottom: "nonlocal3_temp"
  top: "nonlocal3_conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_term: false
  }
}

layer {
	bottom: "p3"
	bottom: "nonlocal3_conv"
	top: "feature3_temp"
	name: "feature3_temp"
	type: "Eltwise"
}



layer {
  name: "feature3_conv"
  type: "Convolution"
  bottom: "feature3_temp"
  top: "feature3_conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    kernel_size: 3
    pad: 1
    stride: 1
    weight_filler {
        type: "msra"
    }
    bias_filler {
        type: "constant"
        value: 0
    }
  }
}

layer {
   name: "feature4_to3"
   type: "InterpAdvance"
   bottom: "feature4"
   bottom: "feature3_conv"
   top: "feature4_to3"
}

layer {
	bottom: "feature3_conv"
	bottom: "feature4_to3"
	top: "feature34"
	name: "feature34"
	type: "Eltwise"
}

layer {
  name: "feature3"
  type: "Convolution"
  bottom: "feature34"
  top: "feature3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    kernel_size: 3
    pad: 1
    stride: 1
    weight_filler {
        type: "msra"
    }
    bias_filler {
        type: "constant"
        value: 0
    }
  }
}


##################################### predict 3
layer {
  name: "predict3"
  type: "Convolution"
  bottom: "feature3"
  top: "predict3"
  param {
    lr_mult: 0.1
    decay_mult: 1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  convolution_param {
    num_output: 1
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CAFFE
  }
}



layer {
   name: "upsample4_in_dsn3"
   type: "InterpAdvance"
   bottom: "predict3"
   bottom: "data"
   top: "up_predict3"
}

layer {
	bottom: "up_predict3"
	bottom: "final_predict4"
	top: "final_predict3"
	name: "final_predict3"
	type: "Eltwise"
}

layer {
  name: "loss3"
  type: "SigmoidCrossEntropyLoss"
  bottom: "final_predict3"
  bottom: "label"
  top: "loss3"
  loss_weight: 1
  include {
    phase: TRAIN
  }
}
layer {
  name: "sigmoid3"
  type: "Sigmoid"
  bottom: "final_predict3"
  top: "sigmoid3"
  include {
    phase: TEST
  }
}



##################################### non-local feature 2
layer {
  name: "conv_theta2"
  type: "Convolution"
  bottom: "p2"
  top: "conv_theta2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_term: false
  }
}

layer {
  name: "conv_fi2"
  type: "Convolution"
  bottom: "p2"
  top: "conv_fi2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_term: false
  }
}

layer {
  name: "conv_g2"
  type: "Convolution"
  bottom: "p2"
  top: "conv_g2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_term: false
  }
}

layer {
    name: "conv_theta2_r1"
    type: "Reshape"
    bottom: "conv_theta2"
    top: "conv_theta2_r1"
    reshape_param {
      shape {
        dim: 0  # copy the dimension from below
        dim: 0
        dim: -1
        # dim: 1
      }
    }
}

layer {
    name: "conv_fi2_r1"
    type: "Reshape"
    bottom: "conv_fi2"
    top: "conv_fi2_r1"
    reshape_param {
      shape {
        dim: 0  # copy the dimension from below
        dim: 0
        dim: -1
        # dim: 1
      }
    }
}

layer {
    name: "conv_g2_r1"
    type: "Reshape"
    bottom: "conv_g2"
    top: "conv_g2_r1"
    reshape_param {
      shape {
        dim: 0  # copy the dimension from below
        dim: 0
        dim: -1
        # dim: 1
      }
    }
}

layer {
   name: "conv_theta2_t1"
   type: "MatrixTransposition"
   bottom: "conv_theta2_r1"
   top: "conv_theta2_t1"
}

layer {
   name: "matrix2_mul1"
   type: "MatrixMultiplication"
   bottom: "conv_theta2_t1"
   bottom: "conv_fi2_r1"
   top: "2mm1"
}


layer {
  name: "softmax2_mm1"
  type: "Softmax"
  bottom: "2mm1"
  top: "2mm1"
  softmax_param {
     axis: 2 #(n,c,w,h) w
  }
}

######## guidence of the last predicted map
layer {
   name: "resize3_to2"
   type: "InterpAdvance"
   bottom: "final_predict3"
   bottom: "conv_theta2"
   top: "s3to2"
}

layer {
    name: "reshape_s3to2"
    type: "Reshape"
    bottom: "s3to2"
    top: "s3to2_r"
    reshape_param {
      shape {
        dim: 0  # copy the dimension from below
        dim: 0
        dim: -1
        # dim: 1
      }
    }
}


layer {
   name: "s3to2_r_t"
   type: "MatrixTransposition"
   bottom: "s3to2_r"
   top: "s3to2_r_t"
}

layer {
   name: "s3to2_mul1"
   type: "MatrixMultiplication"
   bottom: "s3to2_r_t"
   bottom: "s3to2_r"
   top: "23mm1"
}


layer {
  name: "softmax_23mm1"
  type: "Softmax"
  bottom: "23mm1"
  top: "23mm1"
  softmax_param {
     axis: 2 #(n,c,w,h) w
  }
}

layer {
   name: "matrix23_mul1"
   type: "MatrixMultiplication"
   bottom: "2mm1"
   bottom: "23mm1"
   top: "final_2mm1"
}


layer {
  name: "softmax_final_2mm1"
  type: "Softmax"
  bottom: "final_2mm1"
  top: "final_2mm1"
  softmax_param {
     axis: 2 #(n,c,w,h) w
  }
}


layer {
   name: "matrix2_mul2"
   type: "MatrixMultiplicationYt"
   bottom: "final_2mm1"
   bottom: "conv_g2_r1"
   top: "2mm2"
}


layer {
   name: "nonlocal2_r"
   type: "MatrixTransposition"
   bottom: "2mm2"
   top: "nonlocal2_r"
}


layer {
    name: "nonlocal2_temp"
    type: "ReshapeAdvance"
    bottom: "nonlocal2_r"
    bottom: "conv_theta2"
    top: "nonlocal2_temp"
    reshape_param {
      shape {
        dim: 0  # copy the dimension from below
        dim: 0
        dim: -1 # infer it from the other dimensions
        dim: -2 # refer to the bottom[1]
      }
    }
}

layer {
  name: "nonlocal2_conv"
  type: "Convolution"
  bottom: "nonlocal2_temp"
  top: "nonlocal2_conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_term: false
  }
}


layer {
	bottom: "p2"
	bottom: "nonlocal2_conv"
	top: "feature2_temp"
	name: "feature2_temp"
	type: "Eltwise"
}

layer {
  name: "feature2_conv"
  type: "Convolution"
  bottom: "feature2_temp"
  top: "feature2_conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    kernel_size: 3
    pad: 1
    stride: 1
    weight_filler {
        type: "msra"
    }
    bias_filler {
        type: "constant"
        value: 0
    }
  }
}

layer {
   name: "feature3_to2"
   type: "InterpAdvance"
   bottom: "feature3"
   bottom: "feature2_conv"
   top: "feature3_to2"
}

layer {
	bottom: "feature2_conv"
	bottom: "feature3_to2"
	top: "feature23"
	name: "feature23"
	type: "Eltwise"
}

layer {
  name: "feature2"
  type: "Convolution"
  bottom: "feature23"
  top: "feature2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    kernel_size: 3
    pad: 1
    stride: 1
    weight_filler {
        type: "msra"
    }
    bias_filler {
        type: "constant"
        value: 0
    }
  }
}

##################################### predict 2
layer {
  name: "predict2"
  type: "Convolution"
  bottom: "feature2"
  top: "predict2"
  param {
    lr_mult: 0.1
    decay_mult: 1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  convolution_param {
    num_output: 1
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CAFFE
  }
}

layer {
   name: "upsample2_in_dsn2"
   type: "InterpAdvance"
   bottom: "predict2"
   bottom: "data"
   top: "up_predict2"
}

layer {
	bottom: "up_predict2"
	bottom: "final_predict3"
	top: "final_predict2"
	name: "final_predict2"
	type: "Eltwise"
}

layer {
  name: "loss2"
  type: "SigmoidCrossEntropyLoss"
  bottom: "final_predict2"
  bottom: "label"
  top: "loss2"
  loss_weight: 1
  include {
    phase: TRAIN
  }
}
layer {
  name: "sigmoid2"
  type: "Sigmoid"
  bottom: "final_predict2"
  top: "sigmoid2"
  include {
    phase: TEST
  }
}

